{"componentChunkName":"component---src-templates-blog-post-js","path":"/BM25/","webpackCompilationHash":"91a9e76ae362503cd6e8","result":{"data":{"site":{"siteMetadata":{"title":"mic(s)","author":"Michelle"}},"markdownRemark":{"id":"d11ae63a-0dd9-51e5-8b6f-b5188c92d2ea","excerpt":"BM25 The model revolves around the notion of estimating a probablity of relevance for each pair, and ranking documents in relation to a given query in…","html":"<h2>BM25</h2>\n<ul>\n<li>The model revolves around the notion of estimating a probablity of relevance for each pair, and ranking documents in relation to a given query in descending order.</li>\n<li>To make a probabilistic retrieval strategy precise, we need to estimate how terms in documents contribute to relevance, specifically, we wish to know how term frequency, document frequency, document length, and other statistics that we can compute influence judgments about document relevance, and how they can be reasonably combined to estimate the probability of document relevance. We then order documents by decreasing estimated probability of relevance.</li>\n<li>We take a query to be a representation of an individual user’s information need or perhaps search intent. We take <em>relevance</em> to mean the relevance of a document to the information need, as judged by the user.</li>\n<li>\n<p>The assumptions about relevance are as follows:</p>\n<ul>\n<li>Relevance is assumed to be a property of the document given information need only, assessable without reference to other documents.</li>\n<li>The relevance property is assumed to be binary.</li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"","date":null,"description":null}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/BM25/","previous":{"fields":{"slug":"/tf-idf/"},"frontmatter":{"title":"Vector Space Model and TF-IDF"}},"next":null}}}